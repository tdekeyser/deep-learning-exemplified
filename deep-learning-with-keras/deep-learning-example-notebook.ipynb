{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning example with Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data generation\n",
    "We can load a training and validation set using the ImageDataGenerator class from Keras. This ImageDataGenerator object allows to build a data flow that loads a directory of images lazily. In addition, data can be augmented on the fly to increase nuance in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "inference_dir = 'data/inference'\n",
    "im_height = 128\n",
    "im_width = 128\n",
    "im_channels = 3\n",
    "batch_size = 5\n",
    "\n",
    "train_datagenerator = ImageDataGenerator(rescale=1./255,\n",
    "                                         horizontal_flip=True,\n",
    "                                         rotation_range=10,\n",
    "                                         shear_range=0.2,\n",
    "                                         zoom_range=0.2,\n",
    "                                         width_shift_range=0.2,\n",
    "                                         height_shift_range=0.2)\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dataflow = train_datagenerator.flow_from_directory(train_dir,\n",
    "                                                         target_size=(image_height, image_width),\n",
    "                                                         batch_size=batch_size)\n",
    "test_dataflow = test_datagenerator.flow_from_directory(test_dir,\n",
    "                                                       target_size=(image_height, image_width),\n",
    "                                                       batch_size=batch_size)\n",
    "\n",
    "print(\"Classes of the model with their one-hot labels: \", train_dataflow.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron\n",
    "We can try to train a multi-layer perceptron that classifies the images. However, the results will not get much better than random guessing. This is partly due to the inability of this neural network architecture to find valuable features in the high dimensional space of the problem, which is defined by the number of input neurons: `im_height * im_width * im_channels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(im_height, im_width, im_channels)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit_generator(train_dataflow,\n",
    "                    steps_per_epoch=train_dataflow.samples // batch_size,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_dataflow,\n",
    "                    validation_steps=test_dataflow.samples // batch_size)\n",
    "\n",
    "plot(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with a very deep neural net\n",
    "[Transfer learning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.146.1515&rep=rep1&type=pdf) is a way of using pre-trained models and finetuning them for making inferences on new classes. Because large models such as VGG16 or Inception can take days or even weeks to train from scratch, transfer learning is a convenient method that allows us to use some of the best performing models without investing heavily into powerful infrastructure.\n",
    "\n",
    "[MobileNet](https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html) is currently one of the best scalable deep learning models. It is built by Google with a specific focus on mobile devices and environments with restrictive resources. This makes the model interesting both for training, as training can be performed even on basic systems, and for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import Model\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "pretrained_model = MobileNet(weights='imagenet', input_shape = (image_height,image_width,3), include_top=False)\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dropout, Dense\n",
    "\n",
    "# Add a top layer model that can be trained on new classes. Any classifier will do.\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=pretrained_model.output_shape[1:]))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dropout(0.1))\n",
    "top_model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "transfer_learning_model = Model(inputs=pretrained_model.input, outputs=top_model(pretrained_model.output))\n",
    "\n",
    "transfer_learning_model.compile(loss='binary_crossentropy',\n",
    "                                optimizer='adam',\n",
    "                                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}-{val_acc:.2f}.h5',\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=True,\n",
    "                            period=5)\n",
    "\n",
    "training_history = transfer_learning_model.fit_generator(train_dataflow,\n",
    "                    steps_per_epoch=train_dataflow.samples // batch_size,\n",
    "                    epochs=50,\n",
    "                    validation_data=test_dataflow,\n",
    "                    validation_steps=test_dataflow.samples // batch_size,\n",
    "                    callbacks=[checkpoint])\n",
    "\n",
    "plot(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the model for inference\n",
    "We can now predict the classes of new images using the trained model. The model can however easily be fooled due to the limited coverage of the training and test set over real-world examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotdog = read_for_inference('hotdog.jpg')\n",
    "predict(hotdog, transfer_learning_model)\n",
    "\n",
    "pizza = read_for_inference('pizza_2.jpg')\n",
    "predict(pizza, transfer_learning_model)\n",
    "\n",
    "cute_dog = read_for_inference('cute_dog.jpg')\n",
    "predict(cute_dog, transfer_learning_model)\n",
    "\n",
    "shoe = read_for_inference('shoe.jpg')\n",
    "predict(shoe, transfer_learning_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def read_for_inference(path):\n",
    "    return imresize(load_img(os.path.join(inference_dir, path)), (im_height, im_width))/255.\n",
    "\n",
    "def predict(image, model):\n",
    "    prediction = model.predict(np.asarray([image]))\n",
    "    show(image)\n",
    "    show(load_img('data/class_ims/' + str(np.argmax(prediction)) + '.png'))\n",
    "    print(prediction)\n",
    "\n",
    "def show(image):\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def plot(training_history):\n",
    "    plt.plot(training_history.history['acc'])\n",
    "    plt.plot(training_history.history['val_acc'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('model accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
